{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # Functipn to split data into training, validation and test sets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "import glob   # The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. No tilde expansion is done, but *, ?, and character ranges expressed with [] will be correctly matched.\n",
    "import os   # miscellneous operating system interfaces. This module provides a portable way of using operating system dependent functionality. If you just want to read or write a file see open(), if you want to manipulate paths, see the os.path module, and if you want to read all the lines in all the files on the command line see the fileinput module.\n",
    "import random       \n",
    "from tqdm import tqdm \n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve,log_loss\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "import os\n",
    "import time\n",
    "from time import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "# CMAP (extracting relevant transcriptomic profiles)\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "import cmapPy.pandasGEXpress.subset_gctoo as sg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_battery_L1000 import tprofiles_gc_too_func, extract_tprofile, load_train_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading all relevant data frames and csv files ----------------------------------------------------------\n",
    "\n",
    "# clue column metadata with columns representing compounds in common with SPECs 1 & 2\n",
    "clue_sig_in_SPECS = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/init_data_expl/clue_sig_in_SPECS1&2.csv', delimiter = \",\")\n",
    "\n",
    "# clue row metadata with rows representing transcription levels of specific genes\n",
    "clue_gene = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/init_data_expl/clue_geneinfo_beta.txt', delimiter = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_into_tensor(df):\n",
    "    '''Splitting data into two parts:\n",
    "    1. input : the pointer showing where the transcriptomic profile is  \n",
    "    2. target one hot : labels (the correct MoA) '''\n",
    "    \n",
    "    # one-hot encoding labels\n",
    "     # creating tensor from all_data.df\n",
    "    target = torch.tensor(df['moa'].values.astype(np.int64))\n",
    "\n",
    "    # For each row, take the index of the target label\n",
    "    # (which coincides with the score in our case) and use it as the column index to set the value 1.0.” \n",
    "    target_onehot = torch.zeros(target.shape[0], num_classes)\n",
    "    target_onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    \n",
    "    input =  df.drop('moa', axis = 1)\n",
    "    \n",
    "    return input, target_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcriptomic_Profiles(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels):\n",
    "        self.tprofile_labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        ''' The number of data points '''\n",
    "        return len(self.tprofile_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Retreiving the transcriptomic profile and label'''\n",
    "        t_profile = extract_tprofile(idx)          # extract image from csv using index\n",
    "        t_profile = torch.tensor(t_profile)        # turn t profile into a floating torch tensor\n",
    "        label = self.tprofile_labels[idx]          # extract calssification using index\n",
    "        return t_profile, label \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 \n",
    "# parameters\n",
    "params = {'batch_size' : 1,\n",
    "         'num_workers' : 3,\n",
    "         'shuffle' : True,\n",
    "         'prefetch_factor' : 2} \n",
    "          \n",
    "if using_cuda:\n",
    "    device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Training on device {device}. ' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator: training\n",
    "# create a subset with only train indices\n",
    "\n",
    "# create generator that randomly takes indices from the training set\n",
    "training_dataset = Transcriptomic_Profiles(labels)\n",
    "\n",
    "\n",
    "\n",
    "training_generator = torch.utils.data.DataLoader(training_dataset, **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profile, train_labels = next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'profile: {train_profile}, train label: {train_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold(x_train):\n",
    "    \"\"\"\n",
    "    This function perform feature selection on the data, i.e. removes all low-variance features below the\n",
    "    given 'threshold' parameter.\n",
    "    \n",
    "    Args:\n",
    "            x_fold_train: K-fold train data with only phenotypic/morphological features and PCs - pandas \n",
    "            dataframe.\n",
    "            x_fold_val: K-fold validation data with only phenotypic/morphological features and PCs - pandas \n",
    "            dataframe.\n",
    "            df_test_x_copy: test data - pandas dataframe with only phenotypic/morphological features and PCs.\n",
    "    \n",
    "    Returns:\n",
    "            x_fold_train: K-fold train data after feature selection - pandas dataframe.\n",
    "            x_fold_val: K-fold validation data after feature selection - pandas dataframe.\n",
    "            df_test_x_copy: test data - pandas dataframe after feature selection - pandas dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    var_thresh = VarianceThreshold(threshold = 0.8) # sets a variance threshold\n",
    "    var_thresh.fit(x_train) # learn empirical variances from X\n",
    "    x_train = x_train.loc[:,var_thresh.variances_ > 0.8] # locate all variance thresholds above 0.8, keep those columns\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'L1000_training_set_train_2APC1.csv'\n",
    "valid_filename = 'L1000_test_set_train_2APC1.csv'\n",
    "L1000_training, L1000_validation = load_train_valid_data(train_filename, valid_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling training and validation data \n",
    "# May not be necessary given params\n",
    "L1000_training = L1000_training.sample(frac = 1, random_state = 1)\n",
    "L1000_validation = L1000_validation.sample(frac = 1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3c2de8cdb972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cyclo_adr_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mperc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcreate_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_val\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Tomics-CP-Chem-MoA/04_Tomics_Models/Erik_Models/E_training_test_split.py\u001b[0m in \u001b[0;36mcreate_splits\u001b[0;34m(moas, filename_mod, perc_test, need_val)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# if we only want test and training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompound_train_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mcmpd_trai_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompound_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Compound ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mcmpd_tes_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompound_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Compound ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "moas = [\"cyclooxygenase inhibitor\", \"adrenergic receptor antagonist\"]\n",
    "filename_mod = 'cyclo_adr_2'            \n",
    "perc_test = 0.2\n",
    "create_splits(moas,filename_mod, perc_test, need_val= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
